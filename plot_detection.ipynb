{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import os\n",
    "\n",
    "from mxnet import ndarray as nd\n",
    "import mxnet.autograd as ag\n",
    "import mxnet.gluon as gluon\n",
    "import mxnet as mx\n",
    "from mxnet import init\n",
    "from mxnet import image\n",
    "from mxnet import sym\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from faster_rcnn.config import cfg\n",
    "from faster_rcnn.faster_rcnn import FasterRCNN\n",
    "from faster_rcnn.utils import imagenetNormalize, img_resize, img_resize_fix, bbox_inverse_transform, bbox_clip\n",
    "from faster_rcnn.rpn_proposal import proposal_test\n",
    "from faster_rcnn.nms import *\n",
    "from TUPUFaceDataset import TUPUFaceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare testing dataset\n",
    "def test_transformation(data, label):\n",
    "    data = imagenetNormalize(data)\n",
    "    return data, label\n",
    "\n",
    "test_dataset = TUPUFaceDataset(\n",
    "    [\"/world/data-gpu-57/AR/zmp_working_dir/face_detect/wh9_16_shuffle_test.json\"],\n",
    "#     [\"/world/data-gpu-112/zhanglinghan/big-face/big_faces.json\"],\n",
    "    transform=test_transformation,\n",
    "    resize_func=img_resize_fix,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load model from dynamic graph model & eport to static graph model\n",
    "test_datait = mx.gluon.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "ctx = mx.cpu()\n",
    "net = FasterRCNN(\n",
    "    len(cfg.anchor_ratios) * len(cfg.anchor_scales), \n",
    "    cfg.num_classes, \n",
    "#     pretrained_model=\"vgg16\",\n",
    "#     feature_name=\"vgg0_conv12_fwd_output\",\n",
    "    pretrained_model=\"mobilenetv2_0.5\", \n",
    "    feature_name=\"mobilenetv20_features_linearbottleneck12_batchnorm2_fwd_output\",\n",
    "    ctx=ctx)\n",
    "net.init_params(ctx)\n",
    "# net.collect_params().load(\"/world/data-gpu-112/zhanglinghan/face-detect-faster-rcnn-mx/faster-rcnn-vgg16-9anchors/faster-rcnn-vgg16-9anchors-140000.gluonmodel\", ctx)\n",
    "net.collect_params().load(\"/world/data-gpu-112/zhanglinghan/face-detect-faster-rcnn-mx/faster-rcnn-mobilenetv2_0.5-9anchors/faster-rcnn-mobilenetv2_0.5-9anchors-22000.gluonmodel\", ctx)\n",
    "# net.collect_params().load(\"/world/data-gpu-112/zhanglinghan/face-detect-faster-rcnn-mx/faster-rcnn-vgg16-9anchors-multi-gpu/faster-rcnn-vgg16-9anchors-multi-gpu-2000.gluonmodel\", ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detection_result(data, label, bboxes, cls_scores, axis):\n",
    "    _n, _c, h, w = data.shape\n",
    "    data = data[0].as_in_context(mx.cpu(0))\n",
    "    data[0] = data[0] * 0.229 + 0.485\n",
    "    data[1] = data[1] * 0.224 + 0.456\n",
    "    data[2] = data[2] * 0.225 + 0.406\n",
    "    label = label[0].asnumpy()\n",
    "    img = data.asnumpy()\n",
    "#     img = np.array(np.round(img * 255), dtype=np.uint8)\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    bboxes = bboxes.asnumpy()\n",
    "    cls_scores = cls_scores.asnumpy()\n",
    "    axis.imshow(img)\n",
    "    \n",
    "#     # Show ground truth\n",
    "#     for bbox in label:\n",
    "#         axis.add_patch(plt.Rectangle((int(bbox[0]), int(bbox[1])), int(bbox[2])-int(bbox[0]), int(bbox[3])-int(bbox[1]), fill=False, edgecolor=\"green\"))\n",
    "\n",
    "    # NMS by class\n",
    "    for cls_id in range(1, 2):\n",
    "        cur_scores = cls_scores[:, cls_id]\n",
    "        bboxes_pick = bboxes[:, cls_id * 4: (cls_id+1)*4]\n",
    "        cur_scores, bboxes_pick = nms(cur_scores, bboxes_pick, cfg.rcnn_nms_thresh)\n",
    "        print(cur_scores.shape)\n",
    "        for i in range(len(cur_scores)):\n",
    "            if cur_scores[i] >= 0.8:\n",
    "                bbox = bboxes_pick[i]\n",
    "                axis.add_patch(plt.Rectangle((int(bbox[0]), int(bbox[1])), int(bbox[2])-int(bbox[0]), int(bbox[3])-int(bbox[1]), fill=False, edgecolor=\"blue\"))\n",
    "    \n",
    "    for x in range(int(h / 16)):\n",
    "        axis.axhline(16.0 * x, lw=0.5, color='green', zorder=5)\n",
    "    for x in range(int(w / 16)):\n",
    "        axis.axvline(16.0 * x, lw=0.5, color='green', zorder=5)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_img = test_dataset.__len__()\n",
    "num_img = 20\n",
    "figs, axises = plt.subplots(num_img, 1, figsize=(40, 80))\n",
    "plt.gcf().set_dpi(200)\n",
    "for it, (data, label) in enumerate(test_datait):\n",
    "    if it >= num_img:\n",
    "        break\n",
    "    data = data.as_in_context(ctx)\n",
    "#     data = mx.ndarray.ones((1, 3, 270, 480), ctx=ctx) * 0.5\n",
    "    _n, _c, h, w = data.shape\n",
    "    label = label.as_in_context(ctx)\n",
    "    rpn_cls, rpn_reg, f = net.rpn(data)\n",
    "    f_height = f.shape[2]\n",
    "    f_width = f.shape[3]\n",
    "    rpn_bbox_pred = proposal_test(rpn_cls, rpn_reg, f.shape, data.shape, ctx)\n",
    "\n",
    "    # RCNN part\n",
    "    # add batch dimension\n",
    "    rpn_bbox_pred_attach_batchid = mx.nd.concatenate([mx.nd.zeros((rpn_bbox_pred.shape[0], 1), ctx), rpn_bbox_pred], axis=1)\n",
    "    f = mx.nd.ROIPooling(f, rpn_bbox_pred_attach_batchid, (7, 7), 1.0 / 16) # VGG16 based spatial stride=16\n",
    "    rcnn_cls, rcnn_reg = net.rcnn(f)\n",
    "    rcnn_bbox_pred = mx.nd.zeros(rcnn_reg.shape)\n",
    "    for i in range(2):\n",
    "        rcnn_bbox_pred[:, i*4:(i+1)*4] = bbox_clip(bbox_inverse_transform(rpn_bbox_pred, rcnn_reg[:, i*4:(i+1)*4]), h, w)\n",
    "    rcnn_cls = mx.nd.softmax(rcnn_cls)\n",
    "    show_detection_result(data, label, rcnn_bbox_pred, rcnn_cls, axises[it])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_path = \"/world/data-gpu-112/zhanglinghan/face-detect-faster-rcnn-mx/faster-rcnn-mobilenetv2_0.5-9anchors\"\n",
    "_n, _c, h, w = (1, 3, 360, 640)\n",
    "net.rpn.hybridize()\n",
    "rpn_cls, rpn_reg, f = net.rpn(mx.ndarray.ones(shape=(_n, _c, h, w), ctx=ctx))\n",
    "net.rpn.export(os.path.join(save_path, \"faster-rcnn-mobilenetv2_0.5-9anchors-rpn\"))\n",
    "\n",
    "# symnet = mx.symbol.load(os.path.join(save_path, \"faster-rcnn-mobilenetv2_0.5-9anchors-rpn-symbol.json\"))\n",
    "# mx.viz.plot_network(symnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _n, _c = (1, 1176)    # mbnetv2_0.25\n",
    "_n, _c = (1, 2352)    # mbnetv2_0.25\n",
    "# _n, _c = (1, 25088)    # vgg16\n",
    "net.rcnn.hybridize()\n",
    "rcnn_cls, rcnn_reg = net.rcnn(mx.ndarray.ones(shape=(_n, _c), ctx=ctx))\n",
    "net.rcnn.export(os.path.join(save_path, \"faster-rcnn-mobilenetv2_0.5-9anchors-rcnn\"))\n",
    "\n",
    "# symnet = mx.symbol.load(os.path.join(save_path, \"faster-rcnn-mobilenetv2_0.5-9anchors-rcnn-symbol.json\"))\n",
    "# mx.viz.plot_network(symnet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
